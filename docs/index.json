[{"content":"Before the lecture  Quick glance at the wikipedia page of convolution kernels  The lecture \nAfter the lecture Emblematic papers about new architectures to read:\n VGG, Simonyan and Zisserman 2014 Inception, Szegedy et al. CVPR 2015 ResNet, He et al. ECCV 2016 EfficientNet, Tan et al. ICML 2019  Other papers worth reading:\n Dropout, Srivastava et al. JMLR 2014 Batch Normalization, Ioffe et al. ICML 2015  Some blog posts:\n About different architectures that are designed to be fast: 3 Small but Powerful Convolutional Neural Networks The alternative to batch normalization: Normalization in Deep Learning  ","permalink":"/cnn/","summary":"Before the lecture  Quick glance at the wikipedia page of convolution kernels  The lecture \nAfter the lecture Emblematic papers about new architectures to read:\n VGG, Simonyan and Zisserman 2014 Inception, Szegedy et al. CVPR 2015 ResNet, He et al. ECCV 2016 EfficientNet, Tan et al. ICML 2019  Other papers worth reading:\n Dropout, Srivastava et al. JMLR 2014 Batch Normalization, Ioffe et al. ICML 2015  Some blog posts:","title":"Convolutional Neural Network"},{"content":"Before the lecture If you like videos, you can watch (as much as you can) the videos of 3Blue1Brown on Neural Networks:\n  if you need to brush up your skills in linear algebra: Hui\u0026rsquo;s medium blog post  The lecture \nAfter the lecture   Ruder\u0026rsquo;s overview of gradient-descent based optimizer (SGD, momentum, Adam, etc.)\n  try re-deriving by yourself, on a sheet of paper, all the maths that were covered\n  Overview of optimization from the famous \u0026ldquo;deeplearningbook\u0026rdquo;\n  In-depth explications about momentum on distill.pub\n  Neural network playground\n  Karpathy\u0026rsquo;s \u0026ldquo;Yes, you should understand backprop\u0026rdquo;\n  ","permalink":"/dnn/","summary":"Before the lecture If you like videos, you can watch (as much as you can) the videos of 3Blue1Brown on Neural Networks:\n  if you need to brush up your skills in linear algebra: Hui\u0026rsquo;s medium blog post  The lecture \nAfter the lecture   Ruder\u0026rsquo;s overview of gradient-descent based optimizer (SGD, momentum, Adam, etc.)\n  try re-deriving by yourself, on a sheet of paper, all the maths that were covered","title":"Deep Neural Network"},{"content":"This lesson has more math than usual, but it\u0026rsquo;s important that we don\u0026rsquo;t shy away the theory behind deep learning. It will help us build a strong understanding of the algorithms we will code in later sections. If you feel overwhelmed by the math here, please see this review first.\nWe are talking of neural networks, then what is a neuron? Certainly not the kind that is in your brain. While biologically inspired, artificial neurons are very different from the real counterpart, thus for now put aside any comparison with brains.\nThe neurons, or parameters, of our network are floating values. A neuron could be 0.7964, -102.329, or 3912.20238. We group those neurons in matrices, often denoted \\(W\\). These matrices are often accompanied by a bias \\(b\\).\nSingle Output Network Let\u0026rsquo;s have an example of very simple network:\n[Image of a Linear regression]\nLet\u0026rsquo;s decompose this network in three parts:\nInput:\n The input is an image of a digit: \\(X \\in \\mathcal{R}^{W \\times H \\times 1}\\). The first two dimensions \\(W\\) \u0026amp; \\(H\\) are respectively the width and height of the image. The last dimension correspond to the number of channels. Because here the image is in grayscale, there is only one channel, but with color images we have three channels: Red, Blue, and Green (RGB). The network we are learning right now only accepts vectors, not tensors. Thus we are flattening the input into a vector with a single dimension of length \\(W \\times H\\).  Neurons / Parameters:\n We have \\(W \\in \\mathcal{R}^{1 \\times W \\times H}\\) and \\(b \\in \\mathcal{R}\\), respectively the weights and bias. The operation \\(W^T X\\) results in a single output value \\(z \\in \\mathcal{R}\\). Thus \\(z\\) can have a value from \\(-\\infty\\) to \\(+\\infty\\).  Activation:\n We use a non-linear activation \\(\\sigma(z) = \\frac{1}{1 + e^{-z}} \\in [0, 1]\\) called sigmoid It allows us to map \\(z\\) to a probability \\(o\\).  This is a single-layer neural network that can classify images into two classes.\nMultiple Outputs Network Multi-layers Networks Activation Functions Backpropagation Initialization Optimizers ","permalink":"/tmp1234/","summary":"This lesson has more math than usual, but it\u0026rsquo;s important that we don\u0026rsquo;t shy away the theory behind deep learning. It will help us build a strong understanding of the algorithms we will code in later sections. If you feel overwhelmed by the math here, please see this review first.\nWe are talking of neural networks, then what is a neuron? Certainly not the kind that is in your brain. While biologically inspired, artificial neurons are very different from the real counterpart, thus for now put aside any comparison with brains.","title":"Deep Neural Network"},{"content":"The lecture \nAfter the lecture   Blog on auto-encoder, VAE, and beta-VAE\n  Training tricks for GAN\n  Youtube video on the demonstration of VAE\n  Stanford\u0026rsquo;s course on generative models\n  Tutorial on Style Transfer\n  Paper on why Style Transfer works better with VGG than ResNet\n  Lilian Weng on Normalizing Flows\n  Generate yourself amazing artworks with VQGAN+CLIP [Google Colab]\n  [Non-technical] Visual generated by CLIP and BigSleep\n  [Non-technical] Which face is real? Generated by a GAN\n  ","permalink":"/generative/","summary":"The lecture \nAfter the lecture   Blog on auto-encoder, VAE, and beta-VAE\n  Training tricks for GAN\n  Youtube video on the demonstration of VAE\n  Stanford\u0026rsquo;s course on generative models\n  Tutorial on Style Transfer\n  Paper on why Style Transfer works better with VGG than ResNet\n  Lilian Weng on Normalizing Flows\n  Generate yourself amazing artworks with VQGAN+CLIP [Google Colab]","title":"Generative Models"},{"content":"Welcome to this course on Deep Learning for Computer Vision!\nThis course will teach you the fundamentals of Deep Learning applied to images. Each topic will be covered under three different types of materials:\n Lessons, such as this one, accompanied by slides and small quizzes between chapters; Practices, with Google Colab notebooks where we will code actual algorithms; And, quizzes, where you will test your recall on the important notions.  Lessons and practices are essential to learn new materials. However knowledge can be brittle, it\u0026rsquo;s then best to test it with active recall through quizzes. If you\u0026rsquo;re really motivated, you can also download the Anki decks I provide for each lessons. Anki is a space-repetition tools to ingrain deeply knowledge in your memory, and to basically never forget it. I\u0026rsquo;m not kidding, it\u0026rsquo;s a marvel.\nNo more chitchat, let\u0026rsquo;s start.\nA Bit Of History In 1956, the summer workshop of Darmouth was held with prestigious participants (Minsky, Shannon, McCarthy, etc.). This event marked the starting point of Artificial Intelligence as a field on its own. The hopes were high: beating a chess champion, prove math theorems, replace human\u0026rsquo;s works. Following this meeting, Rosenblatt created the perceptron in 1958, a very simplified model of a biological neuron that aimed to classify images. Yes, \u0026ldquo;artificial neural networks\u0026rdquo; and \u0026ldquo;computer vision\u0026rdquo; aren\u0026rsquo;t new.\nDespite these initial progresses, the field suffered from severe cutbacks in funding leading to the first AI winter in the 70s. The expectation were too great compared to what was achieved. This phenomenon occurred again in the 80s. At this point, practical applications came mainly from other approaches than neural networks, the Support-Vector Machines (SVMs) invented in 1992 proved to be useful for the decades to come.\nDuring the same time, Le Cun developped the first Convolutional Neural Network (CNN) which was specialized to work on images. Fast-forward a few years, Deep CNNs became the kind of image classification, first in 2011 with Ciresan, and later in 2012 with AlexNet of Krizhevsky.\nDeep Learning 101 In this course, we will first code a perceptron, the early CNN of Le Cun, and models similar to AlexNet. Then, we will explore the more recent approaches made to Deep Learning. At this point, you may be confused by the terminology: artificial intelligence, machine learning, neural networks, deep learning\u0026hellip; What\u0026rsquo;s their differences?\n    AI vs ML vs DL\n  Machine Learning is a subfield of Artificial Intelligence based on statistical methods. Deep Learning is a subfield of Machine Learning based on deep neural networks.\nDeep Neural Networks, that I\u0026rsquo;ll now abbreviate to DNNs, are made of different modules, exactly like Legos and can be seen as a single function \\(f\\):\n    Computation graph\n  On the left, \\(X\\) is the input. It can be an image, a text, a sound, etc. On the right, \\(f(X)\\) is the result of the function \\(f\\) when applied on \\(X\\). The DNN showcased here is made of four blocks: two linear operations (\\(W_0\\), \\(W_1\\)) and two non-linear operations (\\(\\sigma\\), \\(\\sigma\\)). The former holds parameters which are also known as the network\u0026rsquo;s neurons. The latter are without any parameters.\nWe want to learn the parameters stored in \\(W_0\\) and \\(W_1\\) in order to have a function \\(f\\) suitable to our goal which could be classifying cats and dogs from an image. Following this example, our result \\(f(X)\\) would be a float value between 0 and 1. 0 would indicate that our network is certain that \\(X\\) is an image of cat, and respectively for 1 an image of dog. Most of the time our network is not fully confident and \\(f(X)\\) could be 0.2, 0.4, or even 0.7.\nSo, we want to make sure that \\(f\\) is as certain as possible \u0026mdash;and right\u0026ndash; given an image \\(X\\). To do so, we need a loss function (also called cost function). This new function has to penalize our network if it makes a mistake (i.e. saying cat for a dog image) or if it is too uncertain (i.e. 0.47 for a cat image):\n    Example of the loss function\n  A small loss means that our model is not that bad, and we shouldn\u0026rsquo;t change too much its parameters. On the other hand, a high loss means that we should change a lot of parameters in order to improve.\nIn this course, we will cover how to design our function \\(f\\) (also called model or architecture), what loss function we can choose, and how to actually update our parameters.\nApplications There is a lot of hype currently going about Deep Learning, but is there any actual applications? Yes there are!\n When Siri, Alexa, or Ok Google listen and understand your oral command When your phone unlock itself when it detects your face, like Apple\u0026rsquo;s FaceID Google translate or even your Google search Autonomous driving Faster analysis for radiology AlphaFold 2 recently greatly improved the protein folding problem Better resolution of video games with more FPS with Nvidia\u0026rsquo;s DLSS Faster resolution of computationally intensive physics simulation  And many more.\nEcosystem Deep Learning and Data Science, both in research and industry, is mainly done with the Python programming language. While Python is a very slow language, computation heavy tasks are deferred to a faster language like Fortran or C++.\nFurthermore while programming is usually done on CPUs, it\u0026rsquo;s still too slow for the large amount of compute that deep neural networks need. Thus we will need another piece of hardware: GPUs. Originally designed for computer graphic applications that also do a lot of algebra. This is also the main reason why Deep Learning didn\u0026rsquo;t work before recently, we didn\u0026rsquo;t have the right hardware!\nUnfortunately, GPUs are quite expensive. For this course all coding practice will be done on Google Colab which lend for free GPUs for a few hours. However, you\u0026rsquo;re free to download the exercises and run it on your favorite setting.\nFinally, several Deep Learning frameworks exist: Pytorch, Keras / Tensorflow, Jax, etc. Although Tensorflow greatly improved with its second version, we will use PyTorch. It\u0026rsquo;s a personal opinion, but I feel PyTorch to be more Pythonic and its API is also clearer. But overall, it doesn\u0026rsquo;t make a big difference; if you master PyTorch, we can learn in no time Tensorflow.\nQuiz Now, let\u0026rsquo;s check with a quick quiz our understanding of this chapter:\n   Click to reveal answer\n           $(document).ready(function () { launchQuiz( \"Introduction to Deep Learning\", eval(\"[\\n {Front: \\\"Are artificial neural networks recent?\\\", Back: \\\"No! It dates back from 1958 and Rosenblatt's Perceptron\\\"},\\n {Front: \\\"Is artificial intelligence only Deep Learning?\\\", Back: \\\"No it's only a sub-domain\\\"},\\n {Front: \\\"During the learning of a Neural Network, which part of it is modified?\\\", Back: \\\"Its parameters\\\"},\\n {Front: \\\"How do we call the function that penalize the Neural Network when it makes mistakes?\\\", Back: \\\"Loss function\\\"},\\n {Front: \\\"What is the main reason why neural networks didn't work in the XXth century?\\\", Back: \\\"Because of a lack of \\u003cb\\u003ecomputational power\\u003c/b\\u003e\\\"},\\n {Front: \\\"What programming language is mainly used in Deep Learning?\\\", Back: \\\"Python\\\"},\\n {Front: \\\"Python is slow, then why Deep Learning mainly exists on Python?\\\", Back: \\\"Because Python is binded to efficient C++\\\"},\\n {Front: \\\"What is the fastest hardware to train a neural network? CPU or GPU?\\\", Back: \\\"GPU\\\"},\\n]\"), false, 1 , false ); });  ","permalink":"/introduction/","summary":"Welcome to this course on Deep Learning for Computer Vision!\nThis course will teach you the fundamentals of Deep Learning applied to images. Each topic will be covered under three different types of materials:\n Lessons, such as this one, accompanied by slides and small quizzes between chapters; Practices, with Google Colab notebooks where we will code actual algorithms; And, quizzes, where you will test your recall on the important notions.","title":"Introduction"},{"content":"The lecture \nAfter the lecture Emblematic papers about new architectures to read:\nBlog posts:\n On the Triplet Network Self-Supervised Learning Twitter thread on recent advances in self-supervision  Papers on few-shot learning:\n Triplet Network Siamese Network for one-shot learning  Papers on self-supervision:\n SimCRL MoCo v1 BYOL Barlow Twins  Papers on domain adaptation:\n DANN and its Gradient Reversal Layer AdaptSegNet  Paper on weak-supervision:\n Weak supervised training on Instagram\u0026rsquo;s hashtags  ","permalink":"/lessdata/","summary":"The lecture \nAfter the lecture Emblematic papers about new architectures to read:\nBlog posts:\n On the Triplet Network Self-Supervised Learning Twitter thread on recent advances in self-supervision  Papers on few-shot learning:\n Triplet Network Siamese Network for one-shot learning  Papers on self-supervision:\n SimCRL MoCo v1 BYOL Barlow Twins  Papers on domain adaptation:\n DANN and its Gradient Reversal Layer AdaptSegNet  Paper on weak-supervision:","title":"Less Data"},{"content":"The lecture \nAfter the lecture Emblematic papers about new architectures to read:\nSeries of blog posts:\n Selective Search Fast and Faster R-CNN  Papers:\n Fully Convolutional Network U-Net \u0026amp; its experiments on medical data! DeepLab Axial DeepLab  ","permalink":"/multilabels/","summary":"The lecture \nAfter the lecture Emblematic papers about new architectures to read:\nSeries of blog posts:\n Selective Search Fast and Faster R-CNN  Papers:\n Fully Convolutional Network U-Net \u0026amp; its experiments on medical data! DeepLab Axial DeepLab  ","title":"Multiple Labels"},{"content":"The lecture \nAfter the lecture   The Illustrated Transormer (NLP)\n  Blog on transformers for Vision\n  Suuuuuuuper long list of the recent papers for transformers for Vision\n  More tricks to train a DNN from Karpathy\n  ","permalink":"/archi/","summary":"The lecture \nAfter the lecture   The Illustrated Transormer (NLP)\n  Blog on transformers for Vision\n  Suuuuuuuper long list of the recent papers for transformers for Vision\n  More tricks to train a DNN from Karpathy\n  ","title":"Novel architectures and tricks to train them"},{"content":"Hello! This is the DeepCourse and I\u0026rsquo;m Arthur, a PhD student that loves sharing what I\u0026rsquo;m learning. This course is the new version of a lectures serie I\u0026rsquo;m giving every Fall at the French engineering school EPITA.\nWhat is this Course? This course comprises several methodologies that I think are useful for students:\n First head to the lesson (in yellow) and learn the new topics Then practice by coding algorithms in the multiple exercise session (in orange) Do a larger quiz to see again if you understood well every aspect of the lesson by doing active recall and space-repetition using Anki!  What is Anki? Whether you\u0026rsquo;re still in school or not, it\u0026rsquo;s very probable that you passed several classes by cramming knowledge. It may have provided you a good grade, but you also probably forgot a lot of it.\nCould we learn to have a good grade AND not forgetting long-term AND not passing hours per day to review the topics acquired years ago?\n Yes, we can.  The magic resides in space-repetition. Gwern.net has made a great overview of this concept, but to put it shortly it is the act of reviewing a fact when you\u0026rsquo;re about to forget it. The following image (source) shows the forgetting curve once we memorized the fact for the first time:\n    Projected forgetting curve and space-repetition\n  Reviewing several times, at longer interval each time \u0026ndash;if you do good, helps to avoid forgetting.\nBecause the intervals are getting longer gradually, you won\u0026rsquo;t feel overwhelmed under many cards. For example, I learned a bit more than 8000 cards in various subjects (ranging from math, CS, history, Chinese, geography, arts, etc.) but I rarely have more than a hundred cards to review per day, less than 20min.\nAnki is one of the most popular space-repetition software (SRS), mainly because of its vibrant community that shares decks and addons. It is available on Windows, Mac, Linux, Web browsers, android, and iOS. Note that all but the latter are free (although it\u0026rsquo;s worth it).\nI cannot stress enough how space-repetition is amazing. Please try it.\nAcknowledgements I had many inspiration for this course, here are some:\n Polytechnique\u0026rsquo;s master of Data Science  This is the course Charles Ollion taught me at EPITA. He then task me to taught this course myself at EPITA. Thus this current course is in some part very similar to it.   Sorbonne\u0026rsquo;s RDFIA: a course I\u0026rsquo;m teaching at Sorbonne. Most of the content was done by Thomas Robert and RÃ©mi Cadene. Stanford\u0026rsquo;s famous CS231n Quantum Country which motivated me to make my own course with space-repetition  ","permalink":"/about/","summary":"About","title":"About"},{"content":"   Click to reveal answer\n           $(document).ready(function () { launchQuiz( \"Introduction to Deep Learning\", eval(\"[\\n {Front: \\\"What are the two passes done in a neural network?\\\", Back: \\\"Forward and backward passes\\\"},\\n {Front: \\\"What is the formula of a single neuron?\\\", Back: \\\"\\\\\\\\(f(x) = w x + b\\\\\\\\)\\\"},\\n {Front: \\\"What is the shape of \\\\\\\\(w\\\\\\\\) in a single neuron?\\\", Back: \\\"Vector of shape (Nb_input_dims)\\\"},\\n {Front: \\\"What is the shape of \\\\\\\\(b\\\\\\\\) in a single neuron?\\\", Back: \\\"Scalar value\\\"},\\n {Front: \\\"What is the shape of \\\\\\\\(W\\\\\\\\) in a hidden layer\\\", Back: \\\"Matrix of shape (Nb_hidden_dims x Nb_input_dims)\\\"},\\n {Front: \\\"What is the shape of \\\\\\\\(b\\\\\\\\) in a hidden layer\\\", Back: \\\"Vector of shape (Nb_hidden_dims)\\\"},\\n {Front: \\\"Why do we use non-linear activation in Multi-Layer Perceptron?\\\", Back: \\\"To separate non-linear problems. And stacking multiple layers without activation is mathematically equivalent to a single layer.\\\"},\\n {Front: \\\"Name some non-linear activations?\\\", Back: \\\"Sigmoid, tanh, ReLU\\\"},\\n {Front: \\\"What is the ReLU formula?\\\", Back: \\\"\\\\\\\\(max(0, x)\\\\\\\\)\\\"},\\n {Front: \\\"What is the Sigmoid formula?\\\", Back: \\\"\\\\\\\\(\\\\\\\\frac{1}{1 + e^{-x}}\\\\\\\\)\\\"},\\n {Front: \\\"What is the problem of the sigma in backpropagation?\\\", Back: \\\"The signal can vanish because sigmoid is satured at both extremum\\\"},\\n {Front: \\\"What is the Sigmoid formula?\\\", Back: \\\"\\\\\\\\(\\\\\\\\frac{1}{1 + e^{-x}}\\\\\\\\)\\\"},\\n {Front: \\\"What is the usual classification loss?\\\", Back: \\\"Cross entropy: \\\\\\\\(-\\\\\\\\Sigma_i y_i \\\\\\\\log \\\\\\\\hat{y}_i\\\\\\\\)\\\"},\\n {Front: \\\"What happens if the learning rate is too high?\\\", Back: \\\"The network risks to diverge\\\"},\\n {Front: \\\"What happens if the learning rate is too low?\\\", Back: \\\"The network risks to fall in bad local minima or converging too slowly\\\"},\\n {Front: \\\"What is the difference between Batch Gradient Descent and Stochastic Gradient Descent?\\\", Back: \\\"1: The whole dataset goes through the model at once. 2: One sample at the time goes through the model\\\"},\\n]\"), false, 1 , false ); });  ","permalink":"/quiz/dnn/","summary":"Click to reveal answer\n           $(document).ready(function () { launchQuiz( \"Introduction to Deep Learning\", eval(\"[\\n {Front: \\\"What are the two passes done in a neural network?\\\", Back: \\\"Forward and backward passes\\\"},\\n {Front: \\\"What is the formula of a single neuron?\\\", Back: \\\"\\\\\\\\(f(x) = w x + b\\\\\\\\)\\\"},\\n {Front: \\\"What is the shape of \\\\\\\\(w\\\\\\\\) in a single neuron?\\\", Back: \\\"","title":"Deep Neural Network"},{"content":"","permalink":"/search/","summary":"search","title":"Search"}]