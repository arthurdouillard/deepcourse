{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer - Deepcourse",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84KKnx-09Zj8"
      },
      "source": [
        "<center><h1>Transfer Learning for CNNs</h1></center>\n",
        "\n",
        "<center><h2><a href=\"https://arthurdouillard.com/deepcourse/\">Course link</a></h2></center>\n",
        "\n",
        "To keep your modifications in case you want to come back later to this colab, do *File -> Save a copy in Drive*.\n",
        "\n",
        "If you find a mistake, or know how to improve this notebook, please open an issue [here](https://github.com/arthurdouillard/deepcourse/issues)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJsPg-NU9Vrg",
        "outputId": "bce7873f-3a8f-4601-b9b9-24339f531f35"
      },
      "source": [
        "!rm -rf PetImages *.docx *.txt *zip\n",
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
        "!unzip -q kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-04 15:05:41--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 2.18.233.19, 2a02:26f0:5c:486::e59, 2a02:26f0:5c:4ac::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|2.18.233.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘kagglecatsanddogs_3367a.zip’\n",
            "\n",
            "kagglecatsanddogs_3 100%[===================>] 786.68M   118MB/s    in 6.2s    \n",
            "\n",
            "2021-06-04 15:05:47 (128 MB/s) - ‘kagglecatsanddogs_3367a.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B49vZcqrk9FI",
        "outputId": "17b9c096-e04c-4b97-f222-31eda89fddb3"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjD0yjMt9910"
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltFA8eyWAeaY"
      },
      "source": [
        "Let's create our loaders. Because we will use a model pretrained on imagenet, we need to re-use the exact same preprocessing (here based on imagenet mean and std).\n",
        "\n",
        "If you don't (please try), performance will dramatically suffer. This is a common source of bugs, so I'm sure you will encounter it one day. Therefore, when doing transfer learning but performance is bad, check the preprocessing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AnG-ufVAcBQ"
      },
      "source": [
        "imagenet_mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "imagenet_std = torch.tensor([0.229, 0.224, 0.225])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acVzdbRG-Ng8"
      },
      "source": [
        "First load the dataset whose structure is class_name/id.jpg:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9gKVJso-H5k",
        "outputId": "15dbd30c-53ae-415f-9d28-41f961371f3a"
      },
      "source": [
        "dataset = ImageFolder('PetImages', transform=transform)\n",
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyig0i6k-z94"
      },
      "source": [
        "To be faster we are going to use less than 25k images, but if you have time, use all images: you will get better performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNgLOIud_CZU",
        "outputId": "6dcfe34a-804d-4b58-e99f-a27f57fa3937"
      },
      "source": [
        "dataset, _ = torch.utils.data.random_split(dataset, [2000, 23000])\n",
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxgb6Oml-j7U"
      },
      "source": [
        "Let's split our dataset in train and test (we omit validation for simplicity here, but in real-life project it is super important!):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrRzgaIu-Zk0",
        "outputId": "357bfdb5-6b05-4e79-e9d6-15eafe88d2c4"
      },
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [1500, 500])\n",
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7m7PtcO_rgk"
      },
      "source": [
        "Let's create our loaders. Because we will use a model pretrained on imagenet, we need to re-use the exact same preprocessing (here based on imagenet mean and std).\n",
        "\n",
        "If you don't (please try), performance will dramatically suffer. This is a common source of bugs, so I'm sure you will encounter it one day. Therefore, when doing transfer learning but performance is bad, check the preprocessing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-l20HAB_S2c",
        "outputId": "fb106ba9-8e71-4cdd-8ce7-b6f24b9724f1"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "print(f\"Nb batches in train: {len(train_loader)}\")\n",
        "print(f\"Nb batches in test: {len(test_loader)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb batches in train: 47\n",
            "Nb batches in test: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVK4uzooAryo"
      },
      "source": [
        "Now, we create a ResNet18 model with its weights pretrained on ImageNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP5MouHbAnLU",
        "outputId": "b274a9c0-6115-4e18-821d-120676dd4d10"
      },
      "source": [
        "net = torchvision.models.resnet18(pretrained=True).cuda()\n",
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7rVL1zwMJF4",
        "outputId": "fe598400-dd79-47e8-a909-4363c4ed4d8f"
      },
      "source": [
        "nb_params = sum(p.numel() for p in net.parameters())\n",
        "print('Nb of parameters', nb_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb of parameters 11689512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqY1x2KWIoNs"
      },
      "source": [
        "Notice that the network is finished by a a global avg pooling (`AdaptiveAvgPool2d`) and a classifier (`fc`).\n",
        "\n",
        "We are going to extract the features and dump them on disk. Therefore, we don't need the last fc layer, thus we will replace by an identity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKz3ALw9INjc"
      },
      "source": [
        "net.fc = nn.Identity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcqDzPfxJYKc"
      },
      "source": [
        "def extract_features(loader, net):\n",
        "  pass # TODO\n",
        "  # Return a tensor of features, and a tensor of labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNEIEUofstwo"
      },
      "source": [
        "# Execute this cell to see the solution, but try to do it by yourself before!\n",
        "!wget https://raw.githubusercontent.com/arthurdouillard/deepcourse/master/static/code/cnn/extract.py\n",
        "%pycat extract.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syzUj39eKxRk",
        "outputId": "61c4e32e-b3a4-4c05-ca6d-e96ff3212086"
      },
      "source": [
        "train_features, train_labels = extract_features(train_loader, net)\n",
        "print(train_features.shape, train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1500, 512]) torch.Size([1500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WxcUun4LW68",
        "outputId": "5bf6d551-95e7-49a0-aa9a-93ddede5f4e5"
      },
      "source": [
        "test_features, test_labels = extract_features(test_loader, net)\n",
        "print(test_features.shape, test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([500, 512]) torch.Size([500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3eMrmNIhFU4"
      },
      "source": [
        "Now, let's define a dataset and loader for features instead of images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykBJHc2tLtPE",
        "outputId": "95a20954-f194-47b5-8d9f-68fb167b92e6"
      },
      "source": [
        "class FeaturesDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.labels[index]\n",
        "\n",
        "\n",
        "train_feat_loader = DataLoader(FeaturesDataset(train_features, train_labels), batch_size=64)\n",
        "test_feat_loader = DataLoader(FeaturesDataset(test_features, test_labels), batch_size=64)\n",
        "\n",
        "len(train_feat_loader), len(test_feat_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZZ-hsYtkmRw"
      },
      "source": [
        "def eval_model(net, loader, loss_fn):\n",
        "  net.eval()\n",
        "  acc, loss = 0., 0.\n",
        "  c = 0\n",
        "  for x, y in loader:\n",
        "    with torch.no_grad():\n",
        "      # No need to compute gradient here thus we avoid storing intermediary activations\n",
        "      logits = net(x.cuda()).cpu()\n",
        "\n",
        "    loss += loss_fn(logits, y).item()\n",
        "    preds = logits.argmax(dim=1)\n",
        "    acc += (preds.numpy() == y.numpy()).sum()\n",
        "    c += len(x)\n",
        "\n",
        "  acc /= c\n",
        "  loss /= len(loader)\n",
        "  net.train()\n",
        "  return round(100 * acc, 2), round(loss, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcHVevB9jOjs"
      },
      "source": [
        "And now train a simple linear classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlWItrsXgz2I",
        "outputId": "9c54f436-4550-409d-ac50-2b1abbcb5bab"
      },
      "source": [
        "classifier = nn.Linear(512, 2).cuda()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01)\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for features, labels in train_feat_loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    features, labels = features.cuda(), labels.cuda()\n",
        "    logits = classifier(features)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_acc, train_loss = eval_model(classifier, train_feat_loader, F.cross_entropy)\n",
        "  test_acc, test_loss = eval_model(classifier, test_feat_loader, F.cross_entropy)\n",
        "\n",
        "  print(f\"Epoch {epoch}, train: {train_acc}%/{train_loss}, test: {test_acc}%/{test_loss}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, train: 94.73%/0.21507, test: 94.4%/0.2187\n",
            "Epoch 1, train: 95.27%/0.16476, test: 94.6%/0.16754\n",
            "Epoch 2, train: 95.67%/0.14195, test: 94.4%/0.14547\n",
            "Epoch 3, train: 96.07%/0.12816, test: 95.0%/0.13279\n",
            "Epoch 4, train: 96.4%/0.11853, test: 95.0%/0.1244\n",
            "Epoch 5, train: 96.67%/0.11123, test: 95.0%/0.11836\n",
            "Epoch 6, train: 96.87%/0.10536, test: 95.4%/0.11376\n",
            "Epoch 7, train: 96.93%/0.10045, test: 95.6%/0.11011\n",
            "Epoch 8, train: 97.0%/0.09624, test: 95.8%/0.10714\n",
            "Epoch 9, train: 97.07%/0.09255, test: 95.8%/0.10465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JytwxAO3mwMU"
      },
      "source": [
        "Performances are already great, with only a finetuning of the final classifier!\n",
        "\n",
        "But that's the magic of transfer learning. Try learning from scratch, even a simple dataset as Cat vs Dog, and you will see it is much harder.\n",
        "\n",
        "Moreover, ImageNet is made of 1000 classes. But among these 1000 classes, there are hundred of classes of cats and dogs of different species. Therefore the extracted features are already well defined.\n",
        "\n",
        "# Finetuning the CNN\n",
        "\n",
        "But we can do better. Our previous approach has two drawbacks:\n",
        "- because we extract the features once, we cannot do a different image augmentation at each iteration\n",
        "- we don't tune at all the CNN, which will provide certainly a gain of performances\n",
        "\n",
        "We are now going to tune part of the CNNs. Ideally, if we tune all the CNN we should get the best performance, but the training will also be slower. Therefore for now, we will only tune the last block of our ResNet18, but feel free to try given more time to tune the whole network.\n",
        "\n",
        "Let's enable back the classifier of our ResNet, but this time with only 2 output classes instead of 1000:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ3VGG7-mfLQ"
      },
      "source": [
        "net.fc = nn.Linear(512, 2).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plA1svqUok6o"
      },
      "source": [
        "To know what to freeze, we have to look at the original codebase here: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L144\n",
        "\n",
        "Given the function I provide, `freeze()`, selectively freeze part of the network so that only the final block (called `layer4`) and the classifier (`fc`) are trained:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90vBB5RopArM"
      },
      "source": [
        "def freeze(module):\n",
        "  for param in module.parameters():\n",
        "    param.requires_grad = False\n",
        "  # Important because some layer like BatchNorm have a different behavior in train vs test:\n",
        "  module.eval()\n",
        "\n",
        "\n",
        "# TODO, freeze part of the network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXxo9b_MsYZc"
      },
      "source": [
        "# Execute this cell to see the solution, but try to do it by yourself before!\n",
        "!wget https://raw.githubusercontent.com/arthurdouillard/deepcourse/master/static/code/cnn/freeze.py\n",
        "%pycat freeze.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipc2hN9EoQbs",
        "outputId": "0fc230fe-53e1-4078-dfe9-a05679de0614"
      },
      "source": [
        "optimizer = torch.optim.SGD( # only provide learnable parameters\n",
        "    filter(lambda x: x.requires_grad, net.parameters()), lr=0.01\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for features, labels in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    features, labels = features.cuda(), labels.cuda()\n",
        "    logits = net(features)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_acc, train_loss = eval_model(net, train_loader, F.cross_entropy)\n",
        "  test_acc, test_loss = eval_model(net, test_loader, F.cross_entropy)\n",
        "\n",
        "  print(f\"Epoch {epoch}, train: {train_acc}%/{train_loss}, test: {test_acc}%/{test_loss}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, train: 98.87%/0.04115, test: 98.6%/0.04536\n",
            "Epoch 1, train: 99.0%/0.05112, test: 97.6%/0.06854\n",
            "Epoch 2, train: 99.4%/0.03492, test: 98.0%/0.05846\n",
            "Epoch 3, train: 99.8%/0.02415, test: 98.0%/0.04936\n",
            "Epoch 4, train: 99.87%/0.01804, test: 98.2%/0.04476\n",
            "Epoch 5, train: 99.87%/0.01358, test: 98.0%/0.04325\n",
            "Epoch 6, train: 100.0%/0.00985, test: 98.2%/0.04368\n",
            "Epoch 7, train: 100.0%/0.00824, test: 98.2%/0.04358\n",
            "Epoch 8, train: 100.0%/0.00672, test: 98.0%/0.04587\n",
            "Epoch 9, train: 100.0%/0.00533, test: 98.6%/0.03897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlEBkFGtrh-o"
      },
      "source": [
        "Results should be better, close to 99% in test. Of course, in this case the problem is easy. Unfreezing more of the CNN won't provide large gains.\n",
        "\n",
        "But in general, it's usually better to finetune all the CNN. In order not to \"lose\" the original features learned on ImageNet, we usually do the training learning with a lower learning rate than in training.\n",
        "\n",
        "Finally, transfert learning is very dependent on the similarity of the source (here ImageNet) and target domain (here cat vs dog). If you wanted to apply transfer learning to medical imagery for example, the gain will be much lower.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GF-AhPKrvNg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}